{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Corpora import MovieReviewCorpus\n",
    "from Lexicon import SentimentLexicon\n",
    "from Statistics import SignTest\n",
    "from Classifiers import NaiveBayesText, SVMText\n",
    "#from Extensions import SVMDoc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scipy\n",
    "# pip install gensim <--issue and doesn't work on ipython?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using sentiment lexicon  ---\n",
      "token-only results: 0.68\n",
      "magnitude results:0.68\n",
      "magnitude lexicon results are not significant with respect to token-only\n"
     ]
    }
   ],
   "source": [
    "# retrieve corpus\n",
    "corpus=MovieReviewCorpus(stemming=False,pos=False)\n",
    "\n",
    "# use sign test for all significance testing\n",
    "signTest=SignTest()\n",
    "\n",
    "# location of svmlight binaries \n",
    "# TODO: change this to your local installation\n",
    "svmlight_dir=\"/path/to/svmlight/binaries/\"\n",
    "\n",
    "print(\"--- classifying reviews using sentiment lexicon  ---\")\n",
    "\n",
    "# read in lexicon\n",
    "lexicon=SentimentLexicon()\n",
    "\n",
    "# on average there are more positive than negative words per review (~7.13 more positive than negative per review)\n",
    "# to take this bias into account will use threshold (roughly the bias itself) to make it harder to classify as positive\n",
    "threshold=8\n",
    "\n",
    "# question 0.1\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=False)\n",
    "token_preds=lexicon.predictions\n",
    "print(f\"token-only results: {lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=True)\n",
    "magnitude_preds=lexicon.predictions\n",
    "print(f\"magnitude results:{lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "# question 0.2\n",
    "p_value=signTest.getSignificance(token_preds,magnitude_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"magnitude lexicon results are {significance} with respect to token-only\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using Naive Bayes on held-out test set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adian/Documents/Cambridge/PhD-2/MLMI13/Classifiers.py:150: RuntimeWarning: divide by zero encountered in log\n",
      "  neg_score += np.log(self.condProb['NEG'][word_id])\n",
      "/Users/adian/Documents/Cambridge/PhD-2/MLMI13/Classifiers.py:149: RuntimeWarning: divide by zero encountered in log\n",
      "  pos_score += np.log(self.condProb['POS'][word_id])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without smoothing: 0.51\n",
      "Accuracy using smoothing: 0.82\n",
      "results using smoothing are significant with respect to no smoothing\n"
     ]
    }
   ],
   "source": [
    "# question 1.0\n",
    "print(\"--- classifying reviews using Naive Bayes on held-out test set ---\")\n",
    "NB=NaiveBayesText(smoothing=False,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "# store predictions from classifier\n",
    "non_smoothed_preds=NB.predictions\n",
    "print(f\"Accuracy without smoothing: {NB.getAccuracy():.2f}\")\n",
    "\n",
    "# question 2.0\n",
    "# use smoothing\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "smoothed_preds=NB.predictions\n",
    "# saving this for use later\n",
    "num_non_stemmed_features=len(NB.vocabulary)\n",
    "print(f\"Accuracy using smoothing: {NB.getAccuracy():.2f}\")\n",
    "\n",
    "# question 2.1\n",
    "# see if smoothing significantly improves results\n",
    "p_value=signTest.getSignificance(non_smoothed_preds,smoothed_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using smoothing are {significance} with respect to no smoothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using 10-fold cross-evaluation ---\n",
      "Accuracy: 0.813\n",
      "Std. Dev: 0.02590366769397721\n"
     ]
    }
   ],
   "source": [
    "# question 3.0\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "print(\"--- classifying reviews using 10-fold cross-evaluation ---\")\n",
    "# using previous instantiated object\n",
    "NB.crossValidate(corpus)\n",
    "# using cross-eval for smoothed predictions from now on\n",
    "smoothed_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.3f}\")\n",
    "print(f\"Std. Dev: {NB.getStdDeviation()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- stemming corpus ---\n",
      "--- cross-validating NB using stemming ---\n",
      "Accuracy: 0.811\n",
      "Std. Dev: 0.025\n",
      "results using stemming are not significant with respect to no stemming\n",
      "--- determining the number of features before/after stemming ---\n",
      "vocab size baseline: 52550\n",
      "vocab size stemmed: 32556\n"
     ]
    }
   ],
   "source": [
    "# question 4.0\n",
    "print(\"--- stemming corpus ---\")\n",
    "# retrieve corpus with tokenized text and stemming (using porter)\n",
    "stemmed_corpus=MovieReviewCorpus(stemming=True,pos=False)\n",
    "print(\"--- cross-validating NB using stemming ---\")\n",
    "NB.crossValidate(stemmed_corpus)\n",
    "stemmed_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.3f}\")\n",
    "print(f\"Std. Dev: {NB.getStdDeviation():.3f}\")\n",
    "\n",
    "# TODO Q4.1\n",
    "# see if smoothing significantly improves results\n",
    "p_value=signTest.getSignificance(smoothed_preds,stemmed_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using stemming are {significance} with respect to no stemming\")\n",
    "\n",
    "# TODO Q4.2\n",
    "print(\"--- determining the number of features before/after stemming ---\")\n",
    "print(f\"vocab size baseline: {num_non_stemmed_features}\")\n",
    "print(f\"vocab size stemmed: {len(NB.vocabulary)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- cross-validating naive bayes using smoothing and bigrams ---\n",
      "Accuracy: 0.76\n",
      "Std. Dev: 0.02\n",
      "results using smoothing and bigrams are significant with respect to smoothing only\n",
      "\n",
      "vocab size baseline: 52550\n",
      "vocab size bigram: 500073\n"
     ]
    }
   ],
   "source": [
    "# question Q5.0\n",
    "# cross-validate model using smoothing and bigrams\n",
    "print(\"--- cross-validating naive bayes using smoothing and bigrams ---\")\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "NB.crossValidate(corpus)\n",
    "smoothed_and_bigram_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.2f}\") \n",
    "print(f\"Std. Dev: {NB.getStdDeviation():.2f}\")\n",
    "\n",
    "# see if bigrams significantly improves results on smoothed NB only\n",
    "p_value=signTest.getSignificance(smoothed_preds,smoothed_and_bigram_preds)\n",
    "signifance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using smoothing and bigrams are {signifance} with respect to smoothing only\")\n",
    "\n",
    "# TODO Q5.1\n",
    "print()\n",
    "print(f\"vocab size baseline: {num_non_stemmed_features}\")\n",
    "print(f\"vocab size bigram: {len(NB.vocabulary)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using SVM 10-fold cross-eval ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [00:11<00:00, 154.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.763\n"
     ]
    }
   ],
   "source": [
    "# TODO Q6 and 6.1\n",
    "print(\"--- classifying reviews using SVM 10-fold cross-eval ---\")\n",
    "corpus=MovieReviewCorpus(stemming=False,pos=False)\n",
    "SVM=SVMText(bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "\n",
    "SVM.train(corpus.train)\n",
    "SVM.test(corpus.test)\n",
    "#SVM.crossValidate(corpus)\n",
    "print(f\"Accuracy: {NB.getAccuracy():.3f}\")\n",
    "#print(f\"Std. Dev: {NB.getStdDeviation():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- adding in POS information to corpus ---\n",
      "--- training svm on word+pos features ----\n",
      "--- training svm discarding closed-class words ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [00:12<00:00, 146.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.763\n"
     ]
    }
   ],
   "source": [
    "# TODO Q7\n",
    "print(\"--- adding in POS information to corpus ---\")\n",
    "print(\"--- training svm on word+pos features ----\")\n",
    "corpus=MovieReviewCorpus(stemming=False,pos=True)\n",
    "#SVM=SVMText(bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "\n",
    "#SVM.crossValidate(corpus)\n",
    "#print(f\"Accuracy: {NB.getAccuracy():.3f}\")\n",
    "#print(f\"Std. Dev: {NB.getStdDeviation():.3f}\")\n",
    "\n",
    "\n",
    "print(\"--- training svm discarding closed-class words ---\")\n",
    "SVM=SVMText(bigrams=False,trigrams=False,discard_closed_class=True)\n",
    "\n",
    "SVM.train(corpus.train)\n",
    "SVM.test(corpus.test)\n",
    "#SVM.crossValidate(corpus)\n",
    "print(f\"Accuracy: {SVM.getAccuracy():.3f}\")\n",
    "#print(f\"Std. Dev: {NB.getStdDeviation():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.830\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {SVM.getAccuracy():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"--- using document embeddings ---\")? (<ipython-input-10-a53cf6863dad>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-a53cf6863dad>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print \"--- using document embeddings ---\"\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"--- using document embeddings ---\")?\n"
     ]
    }
   ],
   "source": [
    "# question 8.0\n",
    "print \"--- using document embeddings ---\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
